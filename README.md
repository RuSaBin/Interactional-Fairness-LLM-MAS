# Interactional Fairness in LLM Multi-Agent Systems (LLM-MAS)

[![arXiv](https://img.shields.io/badge/arXiv-2505.12001-b31b1b.svg)](https://arxiv.org/abs/2505.12001)
[![DOI](https://img.shields.io/badge/DOI-10.48550/arXiv.2505.12001-informational.svg)](https://doi.org/10.48550/arXiv.2505.12001)

This repository accompanies the paper **‚ÄúInteractional Fairness in LLM Multi-Agent Systems: An Evaluation Framework‚Äù** and provides scripts and data to explore interactional fairness‚Äîcovering both **Interpersonal fairness** and **Informational fairness**‚Äîin LLM-based multi-agent simulations. The code supports running controlled simulations, basic modeling, and generating analysis/plots aligned with the study‚Äôs framework.  
‚û°Ô∏è Paper: https://arxiv.org/abs/2505.12001  
‚û°Ô∏è DOI: https://doi.org/10.48550/arXiv.2505.12001

## üóÇÔ∏è Repository layout
    interactional_fairness_simulation.py ‚Äì runs the interaction/negotiation simulations (core experiment logic).

    - data_analysis.py ‚Äì analysis utilities/notebooks-in-code for aggregating and inspecting results.

    - plots.py ‚Äì plotting utilities to reproduce figures/visualizations.

    - logisticregression.py, decisiontree.py ‚Äì simple modeling baselines for outcome/acceptance analysis.

    - agent_b_evaluation_contexts.json ‚Äì example/evaluation contexts used in experiments.

    - edge_case_evaluations.csv, summary_table.csv ‚Äì sample result tables for analysis/plots.

    - images/ ‚Äì saved figures/diagrams used in the paper or generated by plots.py.

    - .env (ignored), venv/ (ignored) ‚Äì local environment files, not part of the experiments.


## üìä Reproducing analyses

 1) Run simulations (writes CSVs / artifacts noted in the script)
python interactional_fairness_simulation.py

 2) Run analysis on produced/checked CSVs
python data_analysis.py

 3) Generate figures
python plots.py

## üìù Citation

If you use this repository or the framework in your work, please cite the paper:

Plain text

    Binkyte, R. (2025). Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework. arXiv:2505.12001. https://doi.org/10.48550/arXiv.2505.12001

BibTeX

@article{binkyte2025interactional,
  title         = {Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework},
  author        = {Ruta Binkyte},
  year          = {2025},
  eprint        = {2505.12001},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  doi           = {10.48550/arXiv.2505.12001},
  url           = {https://arxiv.org/abs/2505.12001}
}

## üöÄ Quick start

```bash
# clone
git clone https://github.com/RuSaBin/Interactional-Fairness-LLM-MAS.git
cd Interactional-Fairness-LLM-MAS
# install dependencies
pip install -r requirements.txt
Make sure to use your OPEN AI API key in interactional_fairness_simulation.py or set a OPENAI_API_KEY variable.


